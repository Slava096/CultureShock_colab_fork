{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled25.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Slava096/CultureShock_colab_fork/blob/master/CultureShok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KSVZga-YBjD",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title инструкция\n",
        "#@markdown после заверщения данной ячейки загрузите зарание разделённые дорожки (https://github.com/deezer/spleeter 5stems) в папку data и запустите следующую ечейку\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Download the code\n",
        "!git clone https://github.com/NVlabs/stylegan2.git\n",
        "%cd stylegan2\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))\n",
        "!mkdir data\n",
        "%cd data\n",
        "!wget https://rolux.org/media/stylegan2/vectors/mouth_ratio.npy\n",
        "!wget https://rolux.org/media/stylegan2/vectors/mouth_open.npy\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTq06eOXYN6A",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Пораметры генерации / Generation settings\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.io import wavfile\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "import moviepy.editor\n",
        "\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import pretrained_networks\n",
        "\n",
        "audio = {}\n",
        "#@markdown FPS конечного видео/ Final FPS\n",
        "fps = 30 #@param {type: \"number\"}\n",
        "\n",
        "# https://www.google.com/search?q=death+grips+black+google+download\n",
        "file_type = \".mp3\" #@param [\".waw\", \".mp3\"] {allow-input: true}\n",
        "for mp3_filename in [f for f in os.listdir('data') if f.endswith(file_type)]:\n",
        "    mp3_filename = f'data/{mp3_filename}'\n",
        "    wav_filename = mp3_filename[:-4] + '.wav'\n",
        "    if not os.path.exists(wav_filename):\n",
        "        audio_clip = moviepy.editor.AudioFileClip(mp3_filename)\n",
        "        audio_clip.write_audiofile(wav_filename, fps=44100, nbytes=2, codec='pcm_s16le')\n",
        "    print(wav_filename)\n",
        "    track_name = os.path.basename(wav_filename)[:-4]\n",
        "    print(track_name)\n",
        "    rate, signal = wavfile.read(wav_filename)\n",
        "    signal = np.mean(signal, axis=1) # to mono\n",
        "    signal = np.abs(signal)\n",
        "    seed = signal.shape[0]\n",
        "    duration = signal.shape[0] / rate\n",
        "    frames = int(np.ceil(duration * fps))\n",
        "    samples_per_frame = signal.shape[0] / frames\n",
        "    audio[track_name] = np.zeros(frames, dtype=signal.dtype)\n",
        "    for frame in range(frames):\n",
        "        start = int(round(frame * samples_per_frame))\n",
        "        stop = int(round((frame + 1) * samples_per_frame))\n",
        "        audio[track_name][frame] = np.mean(signal[start:stop], axis=0)\n",
        "    audio[track_name] /= max(audio[track_name])\n",
        "\n",
        "for track in sorted(audio.keys()):\n",
        "    plt.figure(figsize=(8, 3))\n",
        "    plt.title(track)\n",
        "    plt.plot(audio[track])\n",
        "    plt.savefig(f'data/{track}.png')\n",
        "\n",
        "#@markdown Выбор модели / Change model\n",
        "network_pkl = 'gdrive:networks/stylegan2-church-config-f.pkl' #@param [\"gdrive:networks/stylegan2-horse-config-f.pkl\", \"gdrive:networks/stylegan2-ffhq-config-f.pkl\", \"gdrive:networks/stylegan2-church-config-f.pkl\",\"gdrive:networks/stylegan2-cat-config-f.pkl\",\"gdrive:networks/stylegan2-car-config-f.pkl\"] {allow-input: true}\n",
        "_G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "\n",
        "Gs_kwargs = dnnlib.EasyDict()\n",
        "Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "Gs_kwargs.randomize_noise = False\n",
        "Gs_syn_kwargs = dnnlib.EasyDict()\n",
        "Gs_syn_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "Gs_syn_kwargs.randomize_noise = False\n",
        "Gs_syn_kwargs.minibatch_size = 4\n",
        "noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
        "w_avg = Gs.get_var('dlatent_avg')\n",
        "\n",
        "def get_ws(n, frames, seed):\n",
        "    filename = f'data/ws_{n}_{frames}_{seed}.npy'\n",
        "    if not os.path.exists(filename):\n",
        "        src_ws = np.random.RandomState(seed).randn(n, 512)\n",
        "        ws = np.empty((frames, 512))\n",
        "        for i in range(512):\n",
        "            # FIXME: retarded\n",
        "            x = np.linspace(0, 3*frames, 3*len(src_ws), endpoint=False)\n",
        "            y = np.tile(src_ws[:, i], 3)\n",
        "            x_ = np.linspace(0, 3*frames, 3*frames, endpoint=False)\n",
        "            y_ = interp1d(x, y, kind='quadratic', fill_value='extrapolate')(x_)\n",
        "            ws[:, i] = y_[frames:2*frames]\n",
        "        np.save(filename, ws)\n",
        "    else:\n",
        "        ws = np.load(filename)\n",
        "    return ws\n",
        "\n",
        "def mix_styles(wa, wb, ivs):\n",
        "    w = np.copy(wa)\n",
        "    for i, v in ivs:\n",
        "        w[i] = wa[i] * (1 - v) + wb[i] * v\n",
        "    return w\n",
        "\n",
        "def normalize_vector(v):\n",
        "    return v * np.std(w_avg) / np.std(v) + np.mean(w_avg) - np.mean(v)\n",
        "\n",
        "def render_frame(t):\n",
        "    global base_index\n",
        "    frame = np.clip(np.int(np.round(t * fps)), 0, frames - 1)\n",
        "    Base_index_track = \"other\" #@param [\"other\", \"drums\", \"bass\",\"vocals\",\"piano\"] {allow-input: true}\n",
        "    base_index += base_speed * audio[Base_index_track][frame]**2 \n",
        "    base_w = base_ws[int(round(base_index)) % len(base_ws)]\n",
        "    base_w = np.tile(base_w, (18, 1))\n",
        "    psi_audio = \"bass\" #@param [\"other\", \"drums\", \"bass\",\"vocals\",\"piano\"] {allow-input: true}\n",
        "    psi = 0.5 + audio[psi_audio][frame] / 2\n",
        "    base_w = w_avg + (base_w - w_avg) * psi\n",
        "    mix_w = np.tile(mix_ws[frame], (18, 1))\n",
        "    mix_w = w_avg + (mix_w - w_avg) * 0.75\n",
        "    ranges = [range(0, 4), range(4, 8), range(8, 18)]\n",
        "    values1 = \"drums\" #@param [\"other\", \"drums\", \"bass\",\"vocals\",\"piano\"] {allow-input: true}\n",
        "    values2 = \"piano\" #@param [\"other\", \"drums\", \"bass\",\"vocals\",\"piano\"] {allow-input: true}\n",
        "    values3 = \"drums\" #@param [\"other\", \"drums\", \"bass\",\"vocals\",\"piano\"] {allow-input: true}\n",
        "    values = [audio[track][frame] for track in [values1, values2,values3]]\n",
        "    w = mix_styles(base_w, mix_w, zip(ranges, values))\n",
        "    mauth_open_input = 'vocals' #@param [\"other\", \"drums\", \"bass\",\"vocals\",\"piano\"] {allow-input: true}\n",
        "    w += mouth_open * audio[mauth_open_input][frame] * 1.5\n",
        "    image = Gs.components.synthesis.run(np.stack([w]), **Gs_syn_kwargs)[0]\n",
        "    image = PIL.Image.fromarray(image).resize((size, size), PIL.Image.LANCZOS)\n",
        "    return np.array(image)\n",
        "    \n",
        "size = 512 #@param {type: \"number\"}\n",
        "seconds = int(np.ceil(duration))\n",
        "resolution = 10 #@param {type: \"slider\", min: 1, max: 20}\n",
        "base_frames = resolution * frames\n",
        "base_ws = get_ws(seconds, base_frames, seed)\n",
        "print(audio)\n",
        "base_speed = base_frames / sum(audio['other']**2)\n",
        "base_index = 0\n",
        "mix_ws = get_ws(seconds, frames, seed + 1)\n",
        "# https://rolux.org/media/stylegan2/vectors/mouth_ratio.npy\n",
        "mouth_open = normalize_vector(-np.load('data/mouth_ratio.npy'))\n",
        "\n",
        "\n",
        "video_clip = moviepy.editor.VideoClip(render_frame, duration=duration)\n",
        "\n",
        "audio_clip_input = \"/content/stylegan2/data/2.m4a\" #@param {type: \"string\"}\n",
        "\n",
        "mp4_filename = 'data/vstanSuka2.mp4' #@param {type: \"string\"}\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "audio_clip = moviepy.editor.AudioFileClip(audio_clip_input)\n",
        "video_clip = video_clip.set_audio(audio_clip)\n",
        "video_clip.write_videofile(mp4_filename, fps=fps, codec='libx264', audio_codec='aac', bitrate='8M')\n",
        "files.download(mp4_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKk3vLMjuuQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}